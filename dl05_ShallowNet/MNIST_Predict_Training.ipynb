import cv2
import numpy as np
import matplotlib.pyplot as plt
# colab
from google.colab.patches import cv2_imshow
# deep learning
from skimage.exposure import rescale_intensity
from sklearn.preprocessing import LabelBinarizer
from sklearn.metrics import classification_report
from keras.optimizers import SGD
from sklearn.model_selection import train_test_split 
from sklearn.metrics import classification_report 
# l2 
# 경로 잘못해서 일단 뺌
#from preprocessing import ImageToArrayPreprocessor 
#from preprocessing import SimplePreprocessor 
#from datasets import SimpleDatasetLoader
#from preprocessing import shallownet 
from imutils import paths

from keras.models import Sequential
from keras.layers.convolutional import Conv2D
from keras.layers.core import Activation
from keras.layers.core import Flatten
from keras.layers.core import Dense
from keras import backend as K
from keras.preprocessing.image import img_to_array

class SimpleDatasetLoader:
	def __init__(self, preprocessors=None):
				self.preprocessors = preprocessors
		if self.preprocessors is None:
			self.preprocessors = []

	def load(self, imagePaths, verbose=-1):
		data = []
		labels = []
		for (i, imagePath) in enumerate(imagePaths):
			image = cv2.imread(imagePath)
			label = imagePath.split(os.path.sep)[-2]
			if self.preprocessors is not None:
				for p in self.preprocessors:
					image = p.preprocess(image)
			data.append(image)
			labels.append(label)
			if verbose > 0 and i > 0 and (i + 1) % verbose == 0:
				print("[INFO] processed {}/{}".format(i + 1,
					len(imagePaths)))

		return (np.array(data), np.array(labels))

class SimplePreprocessor:
	def __init__(self, width, height, inter=cv2.INTER_AREA):
		self.width = width
		self.height = height
		self.inter = inter

	def preprocess(self, image):
		return cv2.resize(image, (self.width, self.height),
			interpolation=self.inter)

class ImageToArrayPreprocessor:
    def __init__(self, dataFormat=None):
        self.dataFormat = dataFormat

    def preprocess(self, image):
        return img_to_array(image, data_format=self.dataFormat)

class ShallowNet:

	@staticmethod
	def build(width, height, depth, classes):
		model = Sequential()
		inputShape = (height, width, depth)

		if K.image_data_format() == "channels_first":
			inputShape = (depth, height, width)

		model.add(Conv2D(32, (3, 3), padding="same",
			input_shape=inputShape))
		model.add(Activation("relu"))

		model.add(Flatten())
		model.add(Dense(classes))
		model.add(Activation("softmax"))

		return model


# MNIST dataset 이미지, 모델 설정
print("[INFO] loading images...")
args = {'dataset':'/content/gdrive/My Drive/class/datasets/MNIST', 'model':'/content/gdrive/My Drive/class/shallownet_weights_MNIST.hdf5'} 
imagePaths = list(paths.list_images(args['dataset']))

# image preprocessors 초기화
sp = SimplePreprocessor(32, 32)
iap = ImageToArrayPreprocessor()

# 디스크에서 데이터셋 로드하고 range[0,1]의 intensity로 원 픽셀 조절
sdl = SimpleDatasetLoader(preprocessors=[sp, iap])
(data, labels) = sdl.load(imagePaths, verbose=500)
data = data.astype("float") / 255.0

# train 비율 조절
(trainX, testX, trainY, testY) = train_test_split(data, labels,test_size=0.25, train_size= 0.5, random_state=42)

# 레이블들을 integer에서 vector로 변환
trainY = LabelBinarizer().fit_transform(trainY)
testY = LabelBinarizer().fit_transform(testY)

# 최적화와 모델 초기화
print("[INFO] compiling model...")
opt = SGD(lr=0.005)

model = ShallowNet.build(width=32, height=32, depth=3, classes=10)
model.compile(loss="categorical_crossentropy", optimizer=opt,
	metrics=["accuracy"])

# 네트워크 트레이닝
print("[INFO] training network...")
H = model.fit(trainX, trainY, validation_data=(testX, testY),
	batch_size=32, epochs=100, verbose=1)

# 네트워크를 디스크에 저장
print("[INFO] serializing network...")
model.save(args["model"])

# 네트워크 평가
print("[INFO] evaluating network...")
predictions = model.predict(testX, batch_size=32)
print(classification_report(testY.argmax(axis=1),
	predictions.argmax(axis=1),
	target_names=["0", "1", "2", "3", "4", "5", "6", "7", "8", "9"]))

# 트레이닝 득/실 그래프로 표현
plt.style.use("ggplot")
plt.figure()
plt.plot(np.arange(0, 100), H.history["loss"], label="train_loss")
plt.plot(np.arange(0, 100), H.history["val_loss"], label="val_loss")
plt.plot(np.arange(0, 100), H.history["accuracy"], label="train_acc")
plt.plot(np.arange(0, 100), H.history["val_accuracy"], label="val_acc")
plt.title("Training Loss and Accuracy")
plt.xlabel("Epoch #")
plt.ylabel("Loss/Accuracy")
plt.legend()
plt.show()